

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-CN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-CN" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>3. 线性回归 &mdash; 机器学习笔记 0.1 文档</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/rtd-revised.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="索引" href="genindex.html" />
    <link rel="search" title="搜索" href="search.html" />
    <link rel="prev" title="2. 数据预处理" href="DataPreprocess.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> 机器学习笔记
          

          
          </a>

          
            
            
              <div class="version">
                0.1
              </div>
            
            
            <a href="https://wklchris.github.io/Gitbooks/homepage/" style="margin:0pt 2pt">
              · Site Homepage ·
            </a>
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">目录</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Basic.html">1. 基础</a><ul>
<li class="toctree-l2"><a class="reference internal" href="Basic.html#id2">1.1. 为什么要学习机器学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="Basic.html#id3">1.2. 基础概念</a></li>
<li class="toctree-l2"><a class="reference internal" href="Basic.html#id5">1.3. 机器学习的分类</a><ul>
<li class="toctree-l3"><a class="reference internal" href="Basic.html#id6">1.3.1. 监督与无监督学习</a></li>
<li class="toctree-l3"><a class="reference internal" href="Basic.html#id7">1.3.2. 批量学习与在线学习</a></li>
<li class="toctree-l3"><a class="reference internal" href="Basic.html#id8">1.3.3. 基于实例/模型学习</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="Basic.html#id9">1.4. 如何获取数据集</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="DataPreprocess.html">2. 数据预处理</a><ul>
<li class="toctree-l2"><a class="reference internal" href="DataPreprocess.html#id2">2.1. 补全缺失数据</a><ul>
<li class="toctree-l3"><a class="reference internal" href="DataPreprocess.html#id3">2.1.1. 例1：用本特征的均值补全</a></li>
<li class="toctree-l3"><a class="reference internal" href="DataPreprocess.html#id4">2.1.2. 例2：用外部数据的众数补全</a></li>
<li class="toctree-l3"><a class="reference internal" href="DataPreprocess.html#id5">2.1.3. 例3：用给定常数补全</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="DataPreprocess.html#id6">2.2. 数据类型处理</a><ul>
<li class="toctree-l3"><a class="reference internal" href="DataPreprocess.html#id7">2.2.1. 例1：序数编码 OrdinalEncoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="DataPreprocess.html#id8">2.2.2. 例2：独热编码 OneHotEncoder</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="DataPreprocess.html#id9">2.3. 拆分训练集与测试集</a></li>
<li class="toctree-l2"><a class="reference internal" href="DataPreprocess.html#id10">2.4. 特征缩放：标准化与归一化</a><ul>
<li class="toctree-l3"><a class="reference internal" href="DataPreprocess.html#id12">2.4.1. 例1：标准化</a></li>
<li class="toctree-l3"><a class="reference internal" href="DataPreprocess.html#id13">2.4.2. 例2：归一化</a></li>
<li class="toctree-l3"><a class="reference internal" href="DataPreprocess.html#id14">2.4.3. 例3：乘法缩放</a></li>
<li class="toctree-l3"><a class="reference internal" href="DataPreprocess.html#id15">2.4.4. 例4：鲁棒缩放</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">3. 线性回归</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id2">3.1. 简单线性回归</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id3">3.1.1. 残差</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">机器学习笔记</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>3. 线性回归</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/LinearRegression.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <div class="rst-breadcrumbs-buttons" role="navigation" aria-label="breadcrumb navigation">
      
      
        <a href="DataPreprocess.html" class="btn btn-neutral" title="2. 数据预处理" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
  </div>
  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="id1">
<h1>3. 线性回归<a class="headerlink" href="#id1" title="永久链接至标题">¶</a></h1>
<p>本章介绍线性回归的内容．</p>
<p><strong>线性回归（Linear regression）</strong> 是最基础的机器学习模型．在机器学习中，一个含有 <img class="math" src="_images/math/633a2ea1c4b94fbf461dc018bf110b8ef3e1e3a3.svg" alt="p"/> 个自变量的线性回归的真实模型可以用下式描述：</p>
<div class="math">
<p><img src="_images/math/cb2aa840a4ea50a029dc55e395ab9cf9e60b4720.svg" alt="y = b_1 x_1 + b_2 x_2 + \cdots + b_p x_p + b_0 + \epsilon"/></p>
</div><p>其中，模型左侧的 <img class="math" src="_images/math/da350b404bec28a41f5b510b88110463c5c29cb1.svg" alt="y'"/> 表示待预测的标签，各 <img class="math" src="_images/math/a337b5524074db04ef07c69ba902b22ad32e57a0.svg" alt="b_i"/> 表示特征 <img class="math" src="_images/math/176be3e8b605fe2bc20d891fcc3d3720bfd546a6.svg" alt="x_i"/> 的权重，而 <img class="math" src="_images/math/45781458e10010779d0bac2550947736c79be16e.svg" alt="b_0"/> 表示截距，最后误差项 <img class="math" src="_images/math/51fb92cbb8483f39fbf765f9bfaec986ce30513a.svg" alt="\epsilon"/> 服从标准差为 0 的某个正态分布： <img class="math" src="_images/math/87fd0f9fa27468af29320edab5a02f2e5557a4ed.svg" alt="\epsilon \sim N(0,\sigma)"/>．</p>
<p>拟合值记作 <img class="math" src="_images/math/1e183001446316cc138ec150d3c5deff736acd59.svg" alt="\hat{y}"/> ，即我们通过回归得到的模型是：</p>
<div class="math">
<p><img src="_images/math/d2cfbaedfcfc4ae5118494c87a8e0364e0e79c2d.svg" alt="\hat{y} = \hat{b}_1 x_1 + \hat{b}_2 x_2 + \cdots + \hat{b}_p x_p + \hat{b}_0"/></p>
</div><div class="section" id="id2">
<h2>3.1. 简单线性回归<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h2>
<p>只有一个自变量 <img class="math" src="_images/math/e0a7c32de3cea33a502bb0a4f7c5d879238ec187.svg" alt="x"/> 的线性回归模型，我们称为 <strong>简单线性回归（Simple linear regression）</strong> 。</p>
<p>线性回归实质是一种简单的最优化求解，即求得线性系数 <img class="math" src="_images/math/cf637687b0876e84af6fc87bddb1e53fe8aee388.svg" alt="b_1"/> 与截距 <img class="math" src="_images/math/45781458e10010779d0bac2550947736c79be16e.svg" alt="b_0"/> 的估计，使得估计模型与数据集的差别最小。在一般情况下，这个“差别”是通过二次垂直距离定义的，也就是我们通称的最小二乘：</p>
<div class="math">
<p><img src="_images/math/cd4c2c8303ce2eca0f5da2116e50fcb360a2e34c.svg" alt="Q(b_0, b_1) &amp;= \sum_{i=1}^n \left(y_i - (b_0 + b_1 x_i)\right)

(\hat{b}_0, \hat{b}_1) &amp;= \argmin_{b_0, b_1} Q(b_0, b_1)"/></p>
</div><p>其中，<img class="math" src="_images/math/4846369fb6051ac3da95164f1a753e56329323dc.svg" alt="n"/> 是样本数据集的大小。从数学上由偏导数容易证明，函数 <img class="math" src="_images/math/0bb0a074b836f7528ea1650bef55eb85d80acb03.svg" alt="Q(b_0, b_1)"/> 总是在以下取值时达到最小值：</p>
<div class="math">
<p><img src="_images/math/558f50b74fe1ce603a5c8da442766e814e4cdd8a.svg" alt="\hat{b}_1 = \frac{\sum_{i=1}^n (x_i-\bar{x})(y_i - \bar{y})}{\sum_{i=1}^n (x_i-\bar{x})^2}, \quad \hat{b}_0 = \bar{y} - \hat{b_1}\bar{x}"/></p>
</div><p>其中， <img class="math" src="_images/math/21b6838d7efa6efd9dd89439acd541b069a85736.svg" alt="\bar{x}=\frac{1}{n}\sum_{i=1}^n x_i"/> 与 <img class="math" src="_images/math/9088a75c45e159add547d318c6097f751c2038c3.svg" alt="\bar{y}=\frac{1}{n}\sum_{i=1}^n y_i"/> 分别是样本均值。</p>
<p>由此我们得到了线性回归模型，并可以通过该模型求得 <strong>拟合值（Fitted values）</strong> <img class="math" src="_images/math/8ee71ea458c03efd7fc73490decdf585b53414a3.svg" alt="\hat{y}_i\ (i=1, 2, \ldots, n)"/>：</p>
<div class="math">
<p><img src="_images/math/296e57693fef4872b61cc905d42b735c8a9e7d3e.svg" alt="\hat{y_i} = \hat{b}_0 + \hat{b}_1 x_i"/></p>
</div><p>我们利用 Python 生成一个数据集，并实现一个简单线性回归：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Generating Dataset</span>
<span class="n">b0</span><span class="p">,</span> <span class="n">b1</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># 1 column data</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">b0</span> <span class="o">+</span> <span class="n">b1</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">epsilon</span>

<span class="c1"># Regression</span>
<span class="n">regr</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">regr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">regr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Plotting</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;True data&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">yhat</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Fitted line&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;LR model: $\hat{{y}}$ = {:.2f} + {:.2f}$x$&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">regr</span><span class="o">.</span><span class="n">intercept_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">regr</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>下图展示了该简单线性回归的结果：</p>
<p>(<a class="reference external" href="./_static/simple_linear_regression.py">Source code</a>, <a class="reference external" href="./_static/simple_linear_regression.png">png</a>, <a class="reference external" href="./_static/simple_linear_regression.hires.png">hires.png</a>, <a class="reference external" href="./_static/simple_linear_regression.pdf">pdf</a>)</p>
<div class="figure align-center">
<img alt="_images/simple_linear_regression.png" src="_images/simple_linear_regression.png" />
</div>
<div class="section" id="id3">
<h3>3.1.1. 残差<a class="headerlink" href="#id3" title="永久链接至标题">¶</a></h3>
<p>观测值 <img class="math" src="_images/math/90d56f9a24f5c0f6eb083206d7d526e6fb131302.svg" alt="y_i"/> 与拟合值 <img class="math" src="_images/math/72872107cef05039452d605600cf8ae1b9e47386.svg" alt="\hat{y}_i"/> 之间的差值，称为 <strong>残差（Residuals）</strong> ，记作：</p>
<div class="math">
<p><img src="_images/math/fa0346505a1ba078257bdaffb1eba472214b5f15.svg" alt="e_i = y_i - \hat{y}_i = (y_i - \bar{y}) - \hat{b}_1 (x_i - \bar{x})"/></p>
</div><p>残差 <img class="math" src="_images/math/eabf97085c9573ef7d61e9cf6304ae0e731f6d39.svg" alt="e_i"/> 实质上是真实误差项 <img class="math" src="_images/math/be66fed83fdebc1ba63285c17059501135707d8b.svg" alt="\epsilon_i = y_i - (b_0 + b_1 x_i)"/> 的一个估计。残差有容易证得的三个性质：</p>
<div class="math">
<p><img src="_images/math/0af7f4418d1b8c62e500dceccae1cd8029f2415d.svg" alt="\sum_{i=1}^n e_i = 0, \qquad \sum_{i=1}^n x_i e_i = 0, \qquad \sum_{i=1}^n \hat{y}_i e_i = 0."/></p>
</div></div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="DataPreprocess.html" class="btn btn-neutral" title="2. 数据预处理" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, wklchris

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script type="text/javascript" src="_static/translations.js"></script>
    

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>